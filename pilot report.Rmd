---
title: "CARPS Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

[PILOT/COPILOT - TEXT IN SQUARE BRACKETS IS HERE FOR GUIDANCE. COPILOT PLEASE DELETE BEFORE KNITTING THE FINAL REPORT]

# Report Details

[PILOT/COPILOT ENTER RELEVANT REPORT DETAILS HERE]

```{r}
articleID <- NA # insert the article ID code here e.g., "10-3-2015_PS"
reportType <- NA # specify whether this is the 'pilot' report or 'final' report
pilotNames <- Tanainan C. # insert the pilot's name here e.g., "Tom Hardwicke".  If there are multiple cpilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
copilotNames <- NA # # insert the co-pilot's name here e.g., "Michael Frank". If there are multiple co-pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
pilotTTC <- NA # insert the pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
copilotTTC <- NA # insert the co-pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
pilotStartDate <- NA # insert the pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- NA # insert the co-pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- NA # copilot insert the date of final report completion (after any necessary rounds of author assistance) in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

------

#### Methods summary: 

[PILOT/COPILOT write a brief summary of the methods underlying the target outcomes written in your own words]

------

#### Target outcomes: 

[PILOT copy and paste the target outcomes identified in targetOutcomes.md]  

------

[PILOT/COPILOT DO NOT CHANGE THE CODE IN THE CHUNK BELOW]  

```{r global_options, include=FALSE}
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Step 1: Load packages and prepare report object

[PILOT/COPILOT Some useful packages are being loaded below. You can add any additional ones you might need too.]

```{r}
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CARPSreports) # custom report functions
```

[PILOT/COPILOT DO NOT MAKE CHANGES TO THE CODE CHUNK BELOW]

```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

# Step 2: Load data

```{r}
<<<<<<< HEAD
dataNew <- read.csv("data study 1.csv")
dataCompleet=dataNew[dataNew$Finished==1,]
dat=dataCompleet
# Inter-coder reliability -------------------------------------------------
R2=read.csv("Q1dataC1eval_Second rater.csv")
R1=read.csv2("Q1dataC1eval_First rater.csv")
RF=read.csv("EvalFinal.csv")
=======
dat <- read.csv("data study 1.csv")
>>>>>>> e890be8602237f2fe46b5796a666477b2e5e3253
```

# Step 3: Tidy data

```{r}
<<<<<<< HEAD
R2$Power[which(is.na(R2$Power))]=0
R1$Power[which(is.na(R1$Power))]=0

R2$Other.experiments[which(is.na(R2$Other.experiments))]=0
R1$Other.experiments[which(is.na(R1$Other.experiments))]=0

R2$Rule.of.Thumb[which(is.na(R2$Rule.of.Thumb))]=0
R1$Rule.of.Thumb[which(is.na(R1$Rule.of.Thumb))]=0

R2$Practical.constraints[which(is.na(R2$Practical.constraints))]=0
R1$Practical.constraints[which(is.na(R1$Practical.constraints))]=0

R2$As.many.as.possible[which(is.na(R2$As.many.as.possible))]=0
R1$As.many.as.possible[which(is.na(R1$As.many.as.possible))]=0
=======
>>>>>>> e890be8602237f2fe46b5796a666477b2e5e3253
```

# Step 4: Run analysis

## Pre-processing

[you can remove this section if no pre-processing is required]

```{r}
<<<<<<< HEAD
library(devtools)
install_github("nicebread/WRS", subdir="pkg")
install.packages("WRS")
install.packages("MASS")
library(WRS)
library(pwr)
library(MASS)

#number of discrepancies
disP=length(which(R1$Power!=R2$Power))
disO=length(which(R1$Other.experiments!=R2$Other.experiments))
disR=length(which(R1$Rule.of.Thumb!=R2$Rule.of.Thumb))
disPC=length(which(R1$Practical.constraints!=R2$Practical.constraints))
disA=length(which(R1$As.many.as.possible!=R2$As.many.as.possible))

#show discrepancies
R2[which(R1$Power!=R2$Power),]
R2[which(R1$Other.experiments!=R2$Other.experiments),]
R2[which(R1$Rule.of.Thumb!=R2$Rule.of.Thumb),]
R2[which(R1$Practical.constraints!=R2$Practical.constraints),]
R2[which(R1$As.many.as.possible!=R2$As.many.as.possible),]


k=(Po-Pe)/(1-Pe)
=======
>>>>>>> e890be8602237f2fe46b5796a666477b2e5e3253
```

## Descriptive statistics

```{r}
<<<<<<< HEAD
# Methods section description ---------------------------------------------
a <- dim(dataNew)[1]; a # The number of contacted researchers
reportObject <- reproCheck(reportedValue = '499', obtainedValue = a, valueType = 'other')
b <- round(dim(dataNew)[1] / 1135, 2); b # Ibid, in %
reportObject <- reproCheck(reportedValue = '0.44', obtainedValue = b, valueType = 'other')
c <- dim(dat)[1]; c # The number of completed responses
reportObject <- reproCheck(reportedValue = '291', obtainedValue = c, valueType = 'other')
d <- round(dim(dat)[1] / 1135, 2); d # Ibid, in %
reportObject <- reproCheck(reportedValue = '0.26', obtainedValue = d, valueType = 'other')

########
e <- table(dat$Condition);e # Condition division
ae <- as.numeric(e);ae 
reportObject <- reproCheck(reportedValue = '169', obtainedValue = ae, valueType = 'other')
reportObject <- reproCheck(reportedValue = '122', obtainedValue = ae, valueType = 'other')
########

Pe = (sum(R1[,4:8])/(nrow(R1)*5))*(sum(R2[,4:8])/(nrow(R1)*5))+
  ((nrow(R1)*5-sum(R1[,4:8]))/(nrow(R1)*5))*((nrow(R1)*5-sum(R1[,4:8]))/(nrow(R1)*5))	#expected agreement
Po=(nrow(R1)*5-(disP+disO+disR+disPC+disA))/(nrow(R1)*5)		#observed agreement
reportObject <- reproCheck(reportedValue = '0.93', obtainedValue = Po, valueType = 'other')

#Cohen's kappa
k=(Po-Pe)/(1-Pe)
reportObject <- reproCheck(reportedValue = '0.80', obtainedValue = k, valueType = 'other')

# Power mentions
table(RF$Power)
ta <- as.numeric(round(table(RF$Power)[1] / 197, 2))
reportObject <- reproCheck(reportedValue = '0.47', obtainedValue = ta, valueType = 'other')

# Practical constraints mentioned of those mentioning power
table(RF$Practical.constraints[RF$Power == 1])
tb <- as.numeric(round(table(RF$Practical.constraints[RF$Power == 1]) / table(RF$Power)[1], 2))
reportObject <- reproCheck(reportedValue = '0.22', obtainedValue = tb, valueType = 'other')

# Practical constraints
table(RF$Practical.constraints)
tc <- as.numeric(round(table(RF$Practical.constraints) / 197, 2)); tc
reportObject <- reproCheck(reportedValue = '0.20', obtainedValue = tc, valueType = 'other')

# Rule of thumb mention
rt <- table(RF$Rule.of.Thumb)
rt <- round(table(RF$Rule.of.Thumb) / 197, 2)
as <- as.numeric(rt);as
reportObject <- reproCheck(reportedValue = '0.23', obtainedValue = as, valueType = 'other')

# Common practice mention
table(RF$Other.experiments)
td <- as.numeric(round(table(RF$Other.experiments) / 197, 2))
reportObject <- reproCheck(reportedValue = '0.21', obtainedValue = td, valueType = 'other')


###########
# As many as possible mention
table(RF$As.many.as.possible)
te <- as.numeric(round(table(RF$As.many.as.possible) / 197, 2)); te
reportObject <- reproCheck(reportedValue = '0.09', obtainedValue = te, valueType = 'other')
###########

# proportion alpha = .05 and power = .8 -----------------------------------
round(length(which(dat$Q3==.05))/length(na.omit(dat$Q3)), 2)
round(length(which(dat$Q4==.8))/length(na.omit(dat$Q4)), 2)

# Table 1 -----------------------------------------------------------------
m <- tmean(dat$Q3,na.rm=T) 	#alpha estimate
reportObject <- reproCheck(reportedValue = '0.05', obtainedValue = m, valueType = 'mean')

es <- round(tmean(dat$Q5,na.rm=T), 2)	#ES estimate
reportObject <- reproCheck(reportedValue = '0.39', obtainedValue = es, valueType = 'd')

n <- round(tmean(dat$Q6,na.rm=T), 2)	#N estimate 
reportObject <- reproCheck(reportedValue = '34.6', obtainedValue = n, valueType = 'other')

pw <- round(tmean(dat$Q4,na.rm=T), 2)	#reported power estimate 
reportObject <- reproCheck(reportedValue = '0.80', obtainedValue = pw, valueType = 'other')

###########
p <- power.t.test(n = tmean(dat$Q6,na.rm=T), d = tmean(dat$Q5,na.rm=T));p #calculated power (overall) 
reportObject <- reproCheck(reportedValue = '0.35', obtainedValue = p, valueType = 'other')
###########


pi <- round(tmean(dat$Power,na.rm=T), 2)#calculated power (individual) 
reportObject <- reproCheck(reportedValue = '0.40', obtainedValue = pi, valueType = 'other')


bi <- round(tmean(dat$Bias,na.rm=T), 2)	#bias (individual)
reportObject <- reproCheck(reportedValue = '-0.34', obtainedValue = bi, valueType = 'other')
##

# Calculated power --------------------------------------------------------
# Power for n = 20-25 ###############
power.t.test(n = 20, d = .5)
power.t.test(n = 25, d = .5)
############


# % Do not conduct power analyses
round(sum(dat$PowMen == 0) / length(dat$PowMen), 2)


# Reported and calculated power compared ----------------------------------
#difference reported and calculated power
yuendv2(dat$Q4,dat$Power) ##
yuendv2(dat$Q4_C1,dat$PowerC1)	#researchers
yuendv2(dat$Q4_C2,dat$PowerC2)	#reviewers

# Bias
length(which(dat$Bias<0))/length(na.omit(dat$Bias))*100		#prop neg bias ##
length(which(dat$Bias<(-0.5)))/length(na.omit(dat$Bias))*100	#prop large neg bias ##

# Supplementary Online Material Study 1 -----------------------------------

# Table 1 SOM -------------------------------------------------------------
tmean(dat$Q3_C1,na.rm=T) 	#alpha estimate researchers
median(dat$Q3_C1,na.rm=T)     #alpha estimate researchers
tmean(dat$Q3_C2,na.rm=T) 	#alpha estimate reviewers
median(dat$Q3_C2,na.rm=T)     #alpha estimate reviewers

tmean(dat$Q5_C1,na.rm=T)	#ES estimate researchers
median(dat$Q5_C1,na.rm=T)     #ES estimate researchers
tmean(dat$Q5_C2,na.rm=T)	#ES estimate reviewers
median(dat$Q5_C2,na.rm=T)     #ES estimate reviewers

tmean(dat$Q6_C1,na.rm=T)	#N estimate researchers
median(dat$Q6_C1,na.rm=T)     #N estimate researchers
tmean(dat$Q6_C2,na.rm=T)	#N estimate reviewers
median(dat$Q6_C2,na.rm=T)     #N estimate reviewers

tmean(dat$Q4_C1,na.rm=T)	#reported power estimate researchers
median(dat$Q4_C1,na.rm=T)     #power estimate researchers
tmean(dat$Q4_C2,na.rm=T)	#reported power estimate reviewers
median(dat$Q4_C2,na.rm=T)     #power estimate reviewers

#calculated power (overall) researchers
power.t.test(n = tmean(dat$Q6_C1,na.rm=T), d = tmean(dat$Q5_C1,na.rm=T)) #calculated power (overall) 
power.t.test(n = median(dat$Q6_C1,na.rm=T), d = median(dat$Q5_C1,na.rm=T))
#calculated power (overall) reviewers
power.t.test(n = tmean(dat$Q6_C2,na.rm=T), d = tmean(dat$Q5_C2,na.rm=T)) #calculated power (overall) 
power.t.test(n = median(dat$Q6_C2,na.rm=T), d = median(dat$Q5_C2,na.rm=T))

tmean(dat$PowerC1,na.rm=T)	#calculated power (individual) researchers
median(dat$PowerC1,na.rm=T)                #calculated power (individual) researchers
tmean(dat$PowerC2,na.rm=T)	#calculated power (individual) reviewers
median(dat$PowerC2,na.rm=T)                #calculated power (individual) reviewers

tmean(dat$BiasC1,na.rm=T)	#bias researchers
median(dat$BiasC1,na.rm=T)     #bias researchers
tmean(dat$BiasC2,na.rm=T)	#bias (individual) researchers
median(dat$BiasC2,na.rm=T)     #bias (individual) researchers


# Figure S1 ---------------------------------------------------------------

pdf("histogramms.pdf", width=9,height=18)
layout(matrix(1:18,6,3))

hist(dat$Q3,25, xlab="alpha",main="All")
abline(v=tmean(dat$Q3))
abline(v=mean(dat$Q3),lty=2)
abline(v=median(dat$Q3),lty=3)
legend(x = .4, y = 200, lty = c(1, 2, 3), legend = c("Trimmed mean",
                                                     "Mean",
                                                     "Median"),
       bty = 'n')

hist(dat$Q5[which(dat$Q5<=3)],25,main="All", xlab="ES (d)")
abline(v=tmean(dat$Q5))
abline(v=mean(dat$Q5),lty=2)
abline(v=median(dat$Q5),lty=3)

hist(dat$Q6[which(dat$Q6<501)],25,main="All", xlab="n")
abline(v=tmean(dat$Q6))
abline(v=mean(dat$Q6),lty=2)
abline(v=median(dat$Q6),lty=3)

hist(dat$Q4,25,main="All", xlab="Power (reported)")
abline(v=tmean(dat$Q4))
abline(v=mean(dat$Q4),lty=2)
abline(v=median(dat$Q4),lty=3)
legend(x = .05, y = 200, lty = c(1, 2, 3), legend = c("Trimmed mean",
                                                     "Mean",
                                                     "Median"),
       bty = 'n')

hist(dat$Power,25,main="All", xlab="Power (calculated)")
abline(v=tmean(dat$Power,na.rm=T))
abline(v=mean(dat$Power,na.rm=T),lty=2)
abline(v=median(dat$Power,na.rm=T),lty=3)

hist(dat$Bias,25,main="All", xlab="Bias")
abline(v=tmean(dat$Bias,na.rm=T))
abline(v=mean(dat$Bias,na.rm=T),lty=2)
abline(v=median(dat$Bias,na.rm=T),lty=3)

hist(dat$Q3_C1,25, xlab="alpha",main="Researcher")
abline(v=tmean(dat$Q3_C1,na.rm=T))
abline(v=mean(dat$Q3_C1,na.rm=T),lty=2)
abline(v=median(dat$Q3_C1,na.rm=T),lty=3)

hist(dat$Q5_C1[which(dat$Q5_C1<=3)],25,main="Researcher", xlab="ES (d)")
abline(v=tmean(dat$Q5_C1,na.rm=T))
abline(v=mean(dat$Q5_C1,na.rm=T),lty=2)
abline(v=median(dat$Q5_C1,na.rm=T),lty=3)

hist(dat$Q6_C1[which(dat$Q6_C1<501)],25,main="Researcher", xlab="n")
abline(v=tmean(dat$Q6_C1,na.rm=T))
abline(v=mean(dat$Q6_C1,na.rm=T),lty=2)
abline(v=median(dat$Q6_C1,na.rm=T),lty=3)

hist(dat$Q4_C1,25,main="Researcher", xlab="Power (reported)")
abline(v=tmean(dat$Q4_C1,na.rm=T))
abline(v=mean(dat$Q4_C1,na.rm=T),lty=2)
abline(v=median(dat$Q4_C1,na.rm=T),lty=3)

hist(dat$PowerC1,25,main="Researcher", xlab="Power (calculated)")
abline(v=tmean(dat$PowerC1,na.rm=T))
abline(v=mean(dat$PowerC1,na.rm=T),lty=2)
abline(v=median(dat$PowerC1,na.rm=T),lty=3)

hist(dat$BiasC1,25,main="Researcher", xlab="Bias")
abline(v=tmean(dat$BiasC1,na.rm=T))
abline(v=mean(dat$BiasC1,na.rm=T),lty=2)
abline(v=median(dat$BiasC1,na.rm=T),lty=3)

hist(dat$Q3_C2,25, xlab="alpha",main="Reviewer")
abline(v=tmean(dat$Q3_C2,na.rm=T))
abline(v=mean(dat$Q3_C2,na.rm=T),lty=2)
abline(v=median(dat$Q3_C2,na.rm=T),lty=3)

hist(dat$Q5_C2[which(dat$Q5_C2<=3)],25,main="Reviewer", xlab="ES (d)")
abline(v=tmean(dat$Q5_C2,na.rm=T))
abline(v=mean(dat$Q5_C2,na.rm=T),lty=2)
abline(v=median(dat$Q5_C2,na.rm=T),lty=3)

hist(dat$Q6_C2[which(dat$Q6_C2<501)],25,main="Reviewer", xlab="n")
abline(v=tmean(dat$Q6_C2,na.rm=T))
abline(v=mean(dat$Q6_C2,na.rm=T),lty=2)
abline(v=median(dat$Q6_C2,na.rm=T),lty=3)

hist(dat$Q4_C2,25,main="Reviewer", xlab="Power (reported)")
abline(v=tmean(dat$Q4_C2,na.rm=T))
abline(v=mean(dat$Q4_C2,na.rm=T),lty=2)
abline(v=median(dat$Q4_C2,na.rm=T),lty=3)

hist(dat$PowerC2,25,main="Reviewer", xlab="Power (calculated)")
abline(v=tmean(dat$PowerC2,na.rm=T))
abline(v=mean(dat$PowerC2,na.rm=T),lty=2)
abline(v=median(dat$PowerC2,na.rm=T),lty=3)

hist(dat$BiasC2,25,main="Reviewer", xlab="Bias")
abline(v=tmean(dat$BiasC2,na.rm=T))
abline(v=mean(dat$BiasC2,na.rm=T),lty=2)
abline(v=median(dat$BiasC2,na.rm=T),lty=3)

dev.off()

# Differences between researcher and reviewers ----------------------------
# alpha (no variance so ERROR)
yuenv2(dat$Q3_C1,dat$Q3_C2)
#ES
yuenv2(dat$Q5_C1,dat$Q5_C2)
#N
yuenv2(dat$Q6_C1,dat$Q6_C2)
#power
yuenv2(dat$Q4_C1,dat$Q4_C2)		

trimci(dat$PowerC1)			#CI Power researchers
trimci(dat$PowerC2)			#CI Power reviewers

trimci(dat$BiasC1)			#CI Bias researchers
trimci(dat$BiasC2)			#CI Bias reviewers

# Statistical knowledge ---------------------------------------------------
#correlations with statistical knowledge
cor.test(dat$Q9[which(dat$Condition==1)],dat$Power[which(dat$Condition==1)],use="pairwise.complete.obs",method="spearman")
cor.test(dat$Q9[which(dat$Condition==2)],dat$Power[which(dat$Condition==2)],use="pairwise.complete.obs",method="spearman")

cor.test(dat$Q9[which(dat$Condition==1)],dat$Bias[which(dat$Condition==1)],use="pairwise.complete.obs",method="spearman")
cor.test(dat$Q9[which(dat$Condition==2)],dat$Bias[which(dat$Condition==2)],use="pairwise.complete.obs",method="spearman")

# Table 2 SOM-----------------------------------------------------------------
table(dat$Q10) # N
round(table(dat$Q10)/sum(table(dat$Q10))*100) # N in %

setP=setP2=setP3=rep(NA,6)
for(i in 1:6)
{
  setP[i]=tmean(dat$Power[which(dat$Q10==i)],na.rm=T)	#trimmed mean estimated power for each # pub category
  setP2[i]=tmean(dat$Bias[which(dat$Q10==i)],na.rm=T)	#trimmed mean of bias for each # pub category
}
# Trimmed mean power
round(setP, 2)
# Trimmed mean bias
round(setP2, 2)

# Number of publications --------------------------------------------------
#robust regression
Q10b=dat$Q10-3.5		#centering the number of publications 

#power as dependent var
rr2b=rlm(dat$Power~Q10b*as.factor(dat$Condition))
summary(rr2b)
toss=summary(rr2b)$coefficients[,1]/summary(rr2b)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#only condition is significant

#bias as dependent var
rr2bias=rlm(dat$Bias~Q10b*as.factor(dat$Condition))
summary(rr2bias)
toss=summary(rr2bias)$coefficients[,1]/summary(rr2bias)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#no significant effects

#Alpha as dependent var
rr2al=rlm(dat$Q3~Q10b*as.factor(dat$Condition))
summary(rr2al)
toss=summary(rr2al)$coefficients[,1]/summary(rr2al)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#no significant effects

#reported power as dependent var
rr2po=rlm(dat$Q4~Q10b*as.factor(dat$Condition))
summary(rr2po)
toss=summary(rr2po)$coefficients[,1]/summary(rr2po)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#condition is significant, but probably problems due to non variability

#ES as dependent var
rr2es=rlm(dat$Q5~Q10b*as.factor(dat$Condition))
summary(rr2es)
toss=summary(rr2es)$coefficients[,1]/summary(rr2es)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#condition is signifcant

#N as dependent var
rr2N=rlm(dat$Q6~Q10b*as.factor(dat$Condition))
summary(rr2N)
toss=summary(rr2N)$coefficients[,1]/summary(rr2N)$coefficients[,2]
pval=2*(1-pnorm(abs(toss)))
pval
#number of publications is a significant predictor (b = 3.58, p = .002)

# Table 3 SOM -------------------------------------------------------------
#number of respondents per research field
table(dat$Q8)
round(table(dat$Q8)/sum(table(dat$Q8))*100)

#number of respondents in the research condition per research field
table(dat$Q8[which(dat$Condition==1)])
round(table(dat$Q8[which(dat$Condition==1)])/sum(table(dat$Q8[which(dat$Condition==1)]))*100)

#number of respondents in the reviewer condition per research field
table(dat$Q8[which(dat$Condition==2)])
round(table(dat$Q8[which(dat$Condition==2)])/sum(table(dat$Q8[which(dat$Condition==2)]))*100)

# Trimmed mean statistical knowledge
statField=rep(NA,10)
for(i in 1:10)
{
  statField[i]=tmean(dat$Q9[which(dat$Q8==i)])
}
round(statField,1)

#calculate trimmed mean of the calculated power, bias, N, and ES for each research field
## alpha and power are not calculated due to the low variability in the answers of the respondents on this question
set=set2=set3=set4=rep(NA,10)
for(i in 1:10)
{
  set[i]=tmean(dat$Power[which(dat$Q8==i)],na.rm=T)	#calculated power for each research field
  set2[i]=tmean(dat$Bias[which(dat$Q8==i)],na.rm=T)	#Bias for each research field
}
round(set, 2)
round(set2, 2)

# Research field ----------------------------------------------------------
#2 by 9 ANOVA with trimmed means

#difference in estimated power
mEP2w=na.omit(cbind(dat$Power[which(dat$Q8!=4)],dat$Condition[which(dat$Q8!=4)],dat$Q8[which(dat$Q8!=4)]))
zEP2w=fac2list(mEP2w[,1],mEP2w[,2:3])
t2way(2,9,zEP2w)
#no effects

#difference in bias
mB2w=na.omit(cbind(dat$Bias[which(dat$Q8!=4)],dat$Condition[which(dat$Q8!=4)],dat$Q8[which(dat$Q8!=4)]))
zB2w=fac2list(mB2w[,1],mB2w[,2:3])
t2way(2,9,zB2w)
#no effects

#differences in Alpha 
mA2w=na.omit(cbind(dat$Q3[which(dat$Q8!=4)],dat$Condition[which(dat$Q8!=4)],dat$Q8[which(dat$Q8!=4)]))
zA2w=fac2list(mA2w[,1],mA2w[,2:3])
t2way(2,9,zA2w)
## can't be tested due to low variability in the responses

#differences in ES
mES2w=na.omit(cbind(dat$Q5[which(dat$Q8!=4)],dat$Condition[which(dat$Q8!=4)],dat$Q8[which(dat$Q8!=4)]))
zES2w=fac2list(mES2w[,1],mES2w[,2:3])
t2way(2,9,zES2w)
#no main effects, but a small interaction effect between condition and research field (Q = 23.18, p = .032)
#$means
#          [,1] [,2] [,3]   [,4]      [,5]  [,6]      [,7]   [,8]      [,9]
#[1,] 0.3730769 0.40 0.40 0.2875 0.3285714 0.500 0.4035714 0.5000 0.4106061
#[2,] 0.4156250 0.45 0.32 0.4625 0.3650000 0.525 0.2727273 0.3875 0.3005556

#differences in N
mN2w=na.omit(cbind(dat$Q6[which(dat$Q8!=4)],dat$Condition[which(dat$Q8!=4)],dat$Q8[which(dat$Q8!=4)]))
zN2w=fac2list(mN2w[,1],mN2w[,2:3])
t2way(2,9,zN2w)
#main effect of condition Q = 21.44, p = .032
#$means
#         [,1]     [,2]     [,3]  [,4]     [,5]  [,6]     [,7]  [,8]     [,9]
#[1,] 57.30769 21.22222 39.16667 40.00 35.71429 23.00 55.21429 41.25 34.09091
#[2,] 37.50000 33.50000 27.20000 41.25 27.50000 31.25 35.90909 45.00 31.11111
#smallest N voor cognitive and neuroscience 


# Additional Questions ----------------------------------------------------
#difference reviewers and researchers in preference number of studies
mrr=matrix(c(table(dat$Q2_C1),table(dat$Q2_C2)),4,2)
chisq.test(mrr)
sqrt(chisq.test(mrr)$statistic/sum(mrr))


# table s4 ----------------------------------------------------------------

mrr
apply(X = mrr, 2, sum)
round(mrr[,1]/sum(mrr[,1])*100)
round(mrr[,2]/sum(mrr[,2])*100)


# table s5 ----------------------------------------------------------------

#question about removing outliers
table(dat$Q7_C1_v1)
round(table(dat$Q7_C1_v1)/sum(table(dat$Q7_C1_v1))*100)
sum(table(dat$Q7_C1_v1))

table(dat$Q7_C1_v2)
round(table(dat$Q7_C1_v2)/sum(table(dat$Q7_C1_v2))*100)
sum(table(dat$Q7_C1_v2))

table(dat$Q7_C2_v1)
round(table(dat$Q7_C2_v1)/sum(table(dat$Q7_C2_v1))*100)
sum(table(dat$Q7_C2_v1))

table(dat$Q7_C2_v2)
round(table(dat$Q7_C2_v2)/sum(table(dat$Q7_C2_v2))*100)
sum(table(dat$Q7_C2_v2))
=======
>>>>>>> e890be8602237f2fe46b5796a666477b2e5e3253
```

## Inferential statistics

```{r}
<<<<<<< HEAD

=======
>>>>>>> e890be8602237f2fe46b5796a666477b2e5e3253
```

# Step 5: Conclusion

[Please include a text summary describing your findings. If this reproducibility check was a failure, you should note any suggestions as to what you think the likely cause(s) might be.]
  
[PILOT/COPILOT ENTER RELEVANT INFORMATION BELOW]

```{r}
Author_Assistance = FALSE # was author assistance provided? (if so, enter TRUE)

Insufficient_Information_Errors <- 0 # how many discrete insufficient information issues did you encounter?

# Assess the causal locus (discrete reproducibility issues) of any reproducibility errors. Note that there doesn't necessarily have to be a one-to-one correspondance between discrete reproducibility issues and reproducibility errors. For example, it could be that the original article neglects to mention that a Greenhouse-Geisser correct was applied to ANOVA outcomes. This might result in multiple reproducibility errors, but there is a single causal locus (discrete reproducibility issue).

locus_typo <- NA # how many discrete issues did you encounter that related to typographical errors?
locus_specification <- NA # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis <- NA # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data <- NA # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified <- NA # how many discrete issues were there for which you could not identify the cause

# How many of the above issues were resolved through author assistance?
locus_typo_resolved <- NA # how many discrete issues did you encounter that related to typographical errors?
locus_specification_resolved <- NA # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis_resolved <- NA # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data_resolved <- NA # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified_resolved <- NA # how many discrete issues were there for which you could not identify the cause

Affects_Conclusion <- NA # Do any reproducibility issues encounter appear to affect the conclusions made in the original article? TRUE, FALSE, or NA. This is a subjective judgement, but you should taking into account multiple factors, such as the presence/absence of decision errors, the number of target outcomes that could not be reproduced, the type of outcomes that could or could not be reproduced, the difference in magnitude of effect sizes, and the predictions of the specific hypothesis under scrutiny.
```

[PILOT/COPILOT DOD NOT EDIT THE CODE CHUNK BELOW]

```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add variables to report 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR")) | Insufficient_Information_Errors > 0){
  finalOutcome <- "Failure without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Failure despite author assistance"
  }
}else{
  finalOutcome <- "Success without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Success with author assistance"
  }
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, Author_Assistance, finalOutcome, Insufficient_Information_Errors, locus_typo, locus_specification, locus_analysis, locus_data, locus_unidentified, locus_typo_resolved, locus_specification_resolved, locus_analysis_resolved, locus_data_resolved, locus_unidentified_resolved)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "final"){
  write_csv(reportObject, "finalReportDetailed.csv")
  write_csv(reportExtras, "finalReportExtras.csv")
}
```

# Session information

[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
